{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7241fb",
   "metadata": {},
   "source": [
    "Develop a Machine Translation system to translate public information content between English\n",
    "and any Indian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14e6f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.12/dist-packages (0.92)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (0.5.2)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (3.1.0)\n",
      "Requirement already satisfied: morfessor in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.3)\n",
      "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
      "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
      "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.4)\n",
      "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (4.1.0)\n",
      "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2026.1.4)\n",
      "Requirement already satisfied: roman-numerals==4.1.0 in /usr/local/lib/python3.12/dist-packages (from roman-numerals-py>=1.0.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (4.1.0)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece torch indic-nlp-library\n",
    "!pip install git+https://github.com/VarunGumma/IndicTransToolkit.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796f1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.44.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1020688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IndicTransToolkit import IndicProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your actual token from https://huggingface.co/settings/tokens\n",
    "login(token=\"REPLACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1ffffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IndicTransForConditionalGeneration(\n",
       "  (model): IndicTransModel(\n",
       "    (encoder): IndicTransEncoder(\n",
       "      (embed_tokens): Embedding(32322, 1024, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransEncoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): IndicTransDecoder(\n",
       "      (embed_tokens): Embedding(122672, 1024, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransDecoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=122672, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"ai4bharat/indictrans2-en-indic-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, trust_remote_code=True\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name, trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Initialize the IndicProcessor for preprocessing\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ae5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_english_to_marathi(text):\n",
    "    src_lang = \"eng_Latn\"\n",
    "    tgt_lang = \"mar_Deva\"\n",
    "    \n",
    "    # Preprocess the input text\n",
    "    input_sentences = [text]\n",
    "    batch = ip.preprocess_batch(input_sentences, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            **inputs,\n",
    "            max_length=256,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "\n",
    "    # Decode the output\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_text = tokenizer.batch_decode(\n",
    "            output_tokens,\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "    \n",
    "    # Postprocess the output\n",
    "    output_text = ip.postprocess_batch(output_text, lang=tgt_lang)\n",
    "    \n",
    "    return output_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec478c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Text:\n",
      " \n",
      "Wearing a helmet while riding a two-wheeler is mandatory for safety.\n",
      "Follow traffic rules to reduce accidents.\n",
      "\n",
      "\n",
      "Marathi Translation:\n",
      " दुचाकी चालवताना हेल्मेट घालणे सुरक्षेसाठी अनिवार्य आहे. अपघात कमी करण्यासाठी वाहतुकीच्या नियमांचे पालन करा.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "english_text = \"\"\"\n",
    "Wearing a helmet while riding a two-wheeler is mandatory for safety.\n",
    "Follow traffic rules to reduce accidents.\n",
    "\"\"\"\n",
    "\n",
    "marathi_translation = translate_english_to_marathi(english_text)\n",
    "\n",
    "print(\"English Text:\\n\", english_text)\n",
    "print(\"\\nMarathi Translation:\\n\", marathi_translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
